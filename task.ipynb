{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c65c32d",
   "metadata": {},
   "source": [
    "## 딥페이크 범죄 대응을 위한 AI 탐지 모델 경진대회\n",
    "\n",
    "**※주의** : 반드시 본 파일을 이용하여 제출을 수행해야 하며, 파일의 이름은 `task.ipynb`로 유지되어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a9781",
   "metadata": {},
   "source": [
    "* #### 추론 실행 환경\n",
    "    * `python 3.9` 환경\n",
    "    * `CUDA 10.2`, `CUDA 11.8`, `CUDA 12.6`를 지원합니다.\n",
    "    * 각 CUDA 환경에 미리 설치돼있는 torch 버전은 다음 표를 참고하세요.\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th align=\"center\">Python</th>\n",
    "      <th align=\"center\">CUDA</th>\n",
    "      <th align=\"center\">torch</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td align=\"center\" style=\"vertical-align: middle;\">3.8</td>\n",
    "      <td align=\"center\">10.2</td>\n",
    "      <td align=\"center\">1.6.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td align=\"center\" style=\"vertical-align: middle;\">3.9</td>\n",
    "      <td align=\"center\">11.8</td>\n",
    "      <td align=\"center\">1.8.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td align=\"center\">3.10</td>\n",
    "      <td align=\"center\">12.6</td>\n",
    "      <td align=\"center\">2.7.1</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3001744a",
   "metadata": {},
   "source": [
    "* #### CUDA 버전 관련 안내사항  \n",
    "  - 이번 경진대회는 3개의 CUDA 버전을 지원합니다.  \n",
    "  - 참가자는 자신의 모델의 라이브러리 의존성에 맞는 CUDA 환경을 선택하여 모델을 제출하면 됩니다.   \n",
    "  - 각 CUDA 환경에는 기본적으로 torch가 설치되어 있으나, 참가자는 제출하는 CUDA 버전과 호환되는 torch, 필요한 버전의 라이브러리를 `!pip install` 하여 사용하여도 무관합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b530b5",
   "metadata": {},
   "source": [
    "* #### `task.ipynb` 작성 규칙\n",
    "코드는 크게 3가지 파트로 구성되며, 해당 파트의 특성을 지켜서 내용을 편집하세요.   \n",
    "1. **제출용 aifactory 라이브러리 및 추가 필요 라이브러리 설치**\n",
    "    - 채점 및 제출을 위한 aifactory 라이브러리를 설치하는 셀입니다. 이 부분은 수정하지 않고 그대로 실행합니다.\n",
    "    - 그 외로, 모델 추론에 필요한 라이브러리를 직접 설치합니다.\n",
    "2. **추론용 코드 작성**\n",
    "    - 모델 로드, 데이터 전처리, 예측 등 실제 추론을 수행하는 모든 코드를 이 영역에 작성합니다.\n",
    "3. **aif.submit() 함수를 호출하여 최종 결과를 제출**\n",
    "    - **마이 페이지-활동히스토리**에서 발급받은 key 값을 함수의 인자로 정확히 입력해야 합니다.\n",
    "    - **※주의** : 제출하고자 하는 CUDA 환경에 맞는 key를 입력하여야 합니다.\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th align=\"left\">Competition 이름</th>\n",
    "      <th align=\"center\">CUDA</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td align=\"left\">딥페이크 범죄 대응을 위한 AI 탐지 모델 경진대회</td>\n",
    "      <td align=\"center\">11.8</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td align=\"left\">딥페이크 범죄 대응을 위한 AI 탐지 모델 경진대회 CUDA 12.6</td>\n",
    "      <td align=\"center\">12.6</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td align=\"left\">딥페이크 범죄 대응을 위한 AI 탐지 모델 경진대회 CUDA 10.2</td>\n",
    "      <td align=\"center\">10.2</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8e0843",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7e2061",
   "metadata": {},
   "source": [
    "#### 1. 제출용 aifactory 라이브러리 설치\n",
    "※ 결과 전송에 필요하므로 아래와 같이 aifactory 라이브러리가 반드시 최신버전으로 설치될 수 있게끔 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4acd91eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aifactory in d:\\경진대회\\venv\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: pipreqs in d:\\경진대회\\venv\\lib\\site-packages (from aifactory) (0.5.0)\n",
      "Requirement already satisfied: ipynbname in d:\\경진대회\\venv\\lib\\site-packages (from aifactory) (2025.8.0.0)\n",
      "Requirement already satisfied: gdown in d:\\경진대회\\venv\\lib\\site-packages (from aifactory) (5.2.0)\n",
      "Requirement already satisfied: requests in d:\\경진대회\\venv\\lib\\site-packages (from aifactory) (2.32.5)\n",
      "Requirement already satisfied: IPython in d:\\경진대회\\venv\\lib\\site-packages (from aifactory) (8.12.3)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\경진대회\\venv\\lib\\site-packages (from gdown->aifactory) (4.14.2)\n",
      "Requirement already satisfied: filelock in d:\\경진대회\\venv\\lib\\site-packages (from gdown->aifactory) (3.19.1)\n",
      "Requirement already satisfied: tqdm in d:\\경진대회\\venv\\lib\\site-packages (from gdown->aifactory) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\경진대회\\venv\\lib\\site-packages (from beautifulsoup4->gdown->aifactory) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in d:\\경진대회\\venv\\lib\\site-packages (from beautifulsoup4->gdown->aifactory) (4.15.0)\n",
      "Requirement already satisfied: ipykernel in d:\\경진대회\\venv\\lib\\site-packages (from ipynbname->aifactory) (7.1.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in d:\\경진대회\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in d:\\경진대회\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (1.8.17)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in d:\\경진대회\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in d:\\경진대회\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in d:\\경진대회\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (0.2.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in d:\\경진대회\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (1.6.0)\n",
      "Requirement already satisfied: packaging>=22 in d:\\경진대회\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (25.0)\n",
      "Requirement already satisfied: psutil>=5.7 in d:\\경진대회\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (7.1.3)\n",
      "Requirement already satisfied: pyzmq>=25 in d:\\경진대회\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in d:\\경진대회\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in d:\\경진대회\\venv\\lib\\site-packages (from ipykernel->ipynbname->aifactory) (5.14.3)\n",
      "Requirement already satisfied: backcall in d:\\경진대회\\venv\\lib\\site-packages (from IPython->aifactory) (0.2.0)\n",
      "Requirement already satisfied: decorator in d:\\경진대회\\venv\\lib\\site-packages (from IPython->aifactory) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\경진대회\\venv\\lib\\site-packages (from IPython->aifactory) (0.19.2)\n",
      "Requirement already satisfied: pickleshare in d:\\경진대회\\venv\\lib\\site-packages (from IPython->aifactory) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in d:\\경진대회\\venv\\lib\\site-packages (from IPython->aifactory) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\경진대회\\venv\\lib\\site-packages (from IPython->aifactory) (2.19.2)\n",
      "Requirement already satisfied: stack-data in d:\\경진대회\\venv\\lib\\site-packages (from IPython->aifactory) (0.6.3)\n",
      "Requirement already satisfied: colorama in d:\\경진대회\\venv\\lib\\site-packages (from IPython->aifactory) (0.4.6)\n",
      "Requirement already satisfied: wcwidth in d:\\경진대회\\venv\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->IPython->aifactory) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\경진대회\\venv\\lib\\site-packages (from jedi>=0.16->IPython->aifactory) (0.8.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\경진대회\\venv\\lib\\site-packages (from jupyter-client>=8.0.0->ipykernel->ipynbname->aifactory) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\경진대회\\venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->ipynbname->aifactory) (4.5.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\경진대회\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel->ipynbname->aifactory) (1.17.0)\n",
      "Requirement already satisfied: docopt==0.6.2 in d:\\경진대회\\venv\\lib\\site-packages (from pipreqs->aifactory) (0.6.2)\n",
      "Requirement already satisfied: nbconvert<8.0.0,>=7.11.0 in d:\\경진대회\\venv\\lib\\site-packages (from pipreqs->aifactory) (7.16.6)\n",
      "Requirement already satisfied: yarg==0.1.9 in d:\\경진대회\\venv\\lib\\site-packages (from pipreqs->aifactory) (0.1.9)\n",
      "Requirement already satisfied: bleach!=5.0.0 in d:\\경진대회\\venv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (6.3.0)\n",
      "Requirement already satisfied: defusedxml in d:\\경진대회\\venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in d:\\경진대회\\venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (3.1.6)\n",
      "Requirement already satisfied: jupyterlab-pygments in d:\\경진대회\\venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in d:\\경진대회\\venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (2.1.5)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in d:\\경진대회\\venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in d:\\경진대회\\venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (0.10.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in d:\\경진대회\\venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in d:\\경진대회\\venv\\lib\\site-packages (from nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (1.5.1)\n",
      "Requirement already satisfied: webencodings in d:\\경진대회\\venv\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in d:\\경진대회\\venv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in d:\\경진대회\\venv\\lib\\site-packages (from nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (2.21.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in d:\\경진대회\\venv\\lib\\site-packages (from nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (4.25.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\경진대회\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\경진대회\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\경진대회\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\경진대회\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert<8.0.0,>=7.11.0->pipreqs->aifactory) (0.28.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\경진대회\\venv\\lib\\site-packages (from requests->aifactory) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\경진대회\\venv\\lib\\site-packages (from requests->aifactory) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\경진대회\\venv\\lib\\site-packages (from requests->aifactory) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\경진대회\\venv\\lib\\site-packages (from requests->aifactory) (2025.10.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in d:\\경진대회\\venv\\lib\\site-packages (from requests[socks]->gdown->aifactory) (1.7.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\경진대회\\venv\\lib\\site-packages (from stack-data->IPython->aifactory) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\경진대회\\venv\\lib\\site-packages (from stack-data->IPython->aifactory) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\경진대회\\venv\\lib\\site-packages (from stack-data->IPython->aifactory) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U aifactory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0deb93f",
   "metadata": {},
   "source": [
    "* 자신의 모델 추론 실행에 필요한 추가 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ceb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==2.7.1 torchvision==0.22.1 --index-url https://download.pytorch.org/whl/cu126\n",
    "!pip install transformers==4.30.0 datasets==2.19.1\n",
    "!pip install numpy==1.26.4 scipy==1.11.4 scikit-learn==1.3.2\n",
    "!pip install pandas Pillow\n",
    "!pip install opencv-python-headless==4.10.0.82\n",
    "!pip install dlib --no-cache-dir\n",
    "!pip install pytorchvideo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ae6846",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c153a6",
   "metadata": {},
   "source": [
    "##### CPU 전용 테스트용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5203cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==2.7.1 torchvision==0.22.1 torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "# !pip install transformers==4.30.0 datasets==2.19.1\n",
    "# !pip install numpy==1.26.4 scipy==1.11.4 scikit-learn==1.3.2\n",
    "# !pip install pandas Pillow\n",
    "# !pip install opencv-python-headless==4.10.0.82\n",
    "# !pip install dlib --no-cache-dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19999e24",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf1b43e",
   "metadata": {},
   "source": [
    "#### 2. 추론용 코드 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d194e",
   "metadata": {},
   "source": [
    "##### 추론 환경의 기본 경로 구조\n",
    "\n",
    "- 평가 데이터셋 경로: `./data/`\n",
    "   - 채점에 사용될 테스트 데이터셋은 `./data/` 디렉토리 안에 포함되어 있습니다.\n",
    "   - 해당 디렉토리에는 이미지(JPG, PNG)와 동영상(MP4) 파일이 별도의 하위 폴더 없이 혼합되어 있습니다.\n",
    "```bash\n",
    "/aif/\n",
    "└── data/\n",
    "    ├── {이미지 데이터1}.jpg\n",
    "    ├── {이미지 데이터2}.png\n",
    "    ├── {동영상 데이터1}.mp4\n",
    "    ├── {이미지 데이터3}.png\n",
    "    ├── {동영상 데이터2}.mp4\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335719c1",
   "metadata": {},
   "source": [
    "- 모델 및 자원 경로: 예시 : `./model/`\n",
    "   - 추론 스크립트가 실행되는 위치를 기준으로, 제출된 모델 관련 파일들이 위치해야하 하는 상대 경로입니다.\n",
    "   - 학습된 모델 가중치(.pt, .ckpt, .pth 등)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c1810d",
   "metadata": {},
   "source": [
    "* 제출 파일은 `submission.csv`로 저장돼야 합니다.\n",
    "  * submission.csv는 *filename*과 *label* 컬럼으로 구성돼야 합니다.\n",
    "  * filename은 추론한 파일의 이름(확장자 포함), label은 추론 결과입니다. (real:0, fake:1)\n",
    "  * filename은 *string*, label은 *int* 자료형이어야 합니다.\n",
    "  * 추론하는 데이터의 순서는 무작위로 섞여도 상관 없습니다.\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th align=\"center\">filename</th>\n",
    "      <th align=\"center\">label</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td align=\"center\">{이미지 데이터1}.jpg</td>\n",
    "      <td align=\"center\">0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td align=\"center\">{동영상 데이터1}.mp4</td>\n",
    "      <td align=\"center\">1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td colspan=\"2\" align=\"center\">...</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c29c10f",
   "metadata": {},
   "source": [
    "**※ 주의 사항**\n",
    "\n",
    "* argparse 사용시 `args, _ = parser.parse_known_args()`로 인자를 지정하세요.   \n",
    "   - `args = parser.parse_args()`는 jupyter에서 오류가 발생합니다.\n",
    "* return 할 결과물과 양식에 유의하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff1c36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 장치: cpu\n",
      "모델 로드 완료!\n",
      "테스트 샘플 개수: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  58%|█████▊    | 7/12 [00:00<00:00, 14.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] sample_video_1.mp4: Given groups=1, weight of size [24, 3, 1, 3, 3], expected input[1, 16, 3, 224, 224] to have 3 channels, but got 16 channels instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  75%|███████▌  | 9/12 [00:03<00:01,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] sample_video_2.mp4: Given groups=1, weight of size [24, 3, 1, 3, 3], expected input[1, 16, 3, 224, 224] to have 3 channels, but got 16 channels instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  83%|████████▎ | 10/12 [00:04<00:01,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] sample_video_3.mp4: Given groups=1, weight of size [24, 3, 1, 3, 3], expected input[1, 16, 3, 224, 224] to have 3 channels, but got 16 channels instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|█████████▏| 11/12 [00:04<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] sample_video_4.mp4: Given groups=1, weight of size [24, 3, 1, 3, 3], expected input[1, 16, 3, 224, 224] to have 3 channels, but got 16 channels instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 12/12 [00:05<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] sample_video_5.mp4: Given groups=1, weight of size [24, 3, 1, 3, 3], expected input[1, 16, 3, 224, 224] to have 3 channels, but got 16 channels instead\n",
      "submission.csv 저장 완료!\n",
      "저장 위치: submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.scse.scse_model import ScSEModel\n",
    "from model.timesformer.timeSformer_model import TimeSformerModel\n",
    "\n",
    "# =============================\n",
    "# 경로 설정\n",
    "# =============================\n",
    "SCSE_MODEL_PATH = \"./model/weights/scse_best.pth\"\n",
    "TS_MODEL_PATH = \"./model/weights/timeSformer_best.pth\"\n",
    "TEST_DIR = Path(\"./data\")   # 테스트셋 디렉토리\n",
    "SUBMISSION_PATH = Path(\"submission.csv\")\n",
    "\n",
    "IMAGE_EXTS = {\".jpg\", \".jpeg\", \".png\"}\n",
    "VIDEO_EXTS = {\".mp4\", \".avi\", \".mov\", \".mkv\"}\n",
    "\n",
    "# =============================\n",
    "# 모델 설정\n",
    "# =============================\n",
    "IMG_SIZE = 224\n",
    "NUM_FRAMES = 8\n",
    "NUM_CLASSES = 2  # real=0, fake=1 (절대 뒤집지 않음)\n",
    "\n",
    "LABEL_FLIP = False  # 사용 안 함\n",
    "VIDEO_TSF_ALPHA = 0.6  # 비디오에서 TimeSformer 비율\n",
    "\n",
    "# 디바이스\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"사용 장치: {device}\")\n",
    "\n",
    "# =============================\n",
    "# Transform\n",
    "# =============================\n",
    "inference_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# =============================\n",
    "# 비디오 샘플링\n",
    "# =============================\n",
    "def sample_frame_indices(total_frames, num_samples):\n",
    "    \"\"\"학습 시 VideoDataset의 np.linspace 샘플링과 동일.\"\"\"\n",
    "    if total_frames <= 0:\n",
    "        return np.zeros(num_samples, dtype=int)\n",
    "\n",
    "    if total_frames < num_samples:\n",
    "        base = np.linspace(0, total_frames - 1, total_frames).astype(int)\n",
    "        pad = np.full(num_samples - total_frames,\n",
    "                      total_frames - 1, dtype=int)\n",
    "        return np.concatenate([base, pad])\n",
    "\n",
    "    return np.linspace(0, total_frames - 1, num_samples).astype(int)\n",
    "\n",
    "# =============================\n",
    "# 이미지/비디오 로더\n",
    "# =============================\n",
    "def load_image_file(path: Path):\n",
    "    img = Image.open(str(path)).convert(\"RGB\")\n",
    "    tensor = inference_transform(img)\n",
    "    return tensor.unsqueeze(0)  # (1,3,H,W)\n",
    "\n",
    "def load_video_frames(path: Path, num_frames: int):\n",
    "    cap = cv2.VideoCapture(str(path))\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    idxs = sample_frame_indices(total, num_frames)\n",
    "\n",
    "    frames = []\n",
    "    for i in idxs:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(i))\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            frame = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        img = Image.fromarray(frame)\n",
    "        frames.append(inference_transform(img))  # (3,H,W)\n",
    "\n",
    "    cap.release()\n",
    "    return torch.stack(frames, dim=0)  # (T,3,H,W)\n",
    "\n",
    "# =============================\n",
    "# 모델 로딩\n",
    "# =============================\n",
    "# scSE\n",
    "scse_model = ScSEModel(num_classes=NUM_CLASSES)\n",
    "scse_model.load_state_dict(torch.load(\n",
    "    SCSE_MODEL_PATH, map_location=device), strict=False)\n",
    "scse_model = scse_model.to(device).eval()\n",
    "\n",
    "# TimeSformer\n",
    "ts_model = TimeSformerModel(\n",
    "    num_classes=NUM_CLASSES,\n",
    "    num_frames=NUM_FRAMES,\n",
    "    img_size=IMG_SIZE\n",
    ")\n",
    "ts_model.load_state_dict(torch.load(\n",
    "    TS_MODEL_PATH, map_location=device), strict=False)\n",
    "ts_model = ts_model.to(device).eval()\n",
    "\n",
    "print(\"모델 로드 완료!\")\n",
    "\n",
    "# =============================\n",
    "# 추론 함수\n",
    "# =============================\n",
    "def infer_image(path: Path) -> int:\n",
    "    x = load_image_file(path).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = scse_model(x)\n",
    "        prob = F.softmax(logits, dim=1)\n",
    "        pred = prob.argmax(dim=1).item()\n",
    "\n",
    "    return int(pred)\n",
    "\n",
    "def infer_video(path: Path) -> int:\n",
    "    frames = load_video_frames(path, NUM_FRAMES)\n",
    "\n",
    "    ts_input = frames.unsqueeze(0).to(device)   # (1,T,3,H,W)\n",
    "    scse_input = frames.to(device)             # (T,3,H,W)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # TimeSformer\n",
    "        if device.type == \"cuda\":\n",
    "            with torch.cuda.amp.autocast():\n",
    "                ts_logits = ts_model(ts_input)\n",
    "        else:\n",
    "            ts_logits = ts_model(ts_input)\n",
    "\n",
    "        ts_prob = F.softmax(ts_logits, dim=1)  # (1,2)\n",
    "\n",
    "        # scSE\n",
    "        scse_logits = scse_model(scse_input)  # (T,2)\n",
    "        scse_prob = F.softmax(scse_logits, dim=1).mean(dim=0, keepdim=True)\n",
    "\n",
    "        # 앙상블\n",
    "        final_prob = VIDEO_TSF_ALPHA * ts_prob + (1 - VIDEO_TSF_ALPHA) * scse_prob\n",
    "\n",
    "        pred = final_prob.argmax(dim=1).item()\n",
    "\n",
    "    return int(pred)\n",
    "\n",
    "# =============================\n",
    "# 전체 파일 추론 & CSV 저장\n",
    "# =============================\n",
    "def run_inference():\n",
    "    files = sorted([p for p in TEST_DIR.iterdir() if p.is_file()])\n",
    "\n",
    "    print(\"테스트 샘플 개수:\", len(files))\n",
    "    results = {}\n",
    "\n",
    "    for path in tqdm(files, desc=\"Processing\"):\n",
    "        ext = path.suffix.lower()\n",
    "\n",
    "        try:\n",
    "            if ext in IMAGE_EXTS:\n",
    "                pred = infer_image(path)\n",
    "            elif ext in VIDEO_EXTS:\n",
    "                pred = infer_video(path)\n",
    "            else:\n",
    "                pred = 0\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {path.name}: {e}\")\n",
    "            pred = 0\n",
    "\n",
    "        results[path.name] = pred\n",
    "\n",
    "    # CSV 저장\n",
    "    with open(SUBMISSION_PATH, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"filename\", \"label\"])\n",
    "\n",
    "        for p in files:\n",
    "            writer.writerow([p.name, results[p.name]])\n",
    "\n",
    "    print(\"submission.csv 저장 완료!\")\n",
    "    print(f\"저장 위치: {SUBMISSION_PATH}\")\n",
    "\n",
    "run_inference()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6119d40d",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f895e41",
   "metadata": {},
   "source": [
    "#### 3. `aif.submit()` 함수를 호출하여 최종 결과를 제출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8410d97e",
   "metadata": {},
   "source": [
    "**※주의** : task별, 참가자별로 key가 다릅니다. 잘못 입력하지 않도록 유의바랍니다.\n",
    "- key는 대회 페이지 [베이스라인 코드](https://aifactory.space/task/9197/baseline) 탭에 기재된 가이드라인을 따라 task 별로 확인하실 수 있습니다.\n",
    "- key가 틀리면 제출이 진행되지 않거나 잘못 제출되므로 task에 맞는 자신의 key를 사용해야 합니다.\n",
    "-  **NOTE** : 이번 경진대회에서는 3개의 CUDA 버전을 지원하며, 각 CUDA 버전에 따라 task key가 상이합니다. 함수를 실행하기 전에 현재 key가 제출하고자 하는 CUDA 환경에 대한 key인지 반드시 확인하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4df34c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file : task\n",
      "jupyter notebook\n",
      "제출 완료\n",
      "45.15132021903992\n"
     ]
    }
   ],
   "source": [
    "import aifactory.score as aif\n",
    "import time\n",
    "t = time.time()\n",
    "\n",
    "#-----------------------------------------------------#\n",
    "aif.submit(model_name=\"scSE-x3ds_test\",\n",
    "    key=\"My-KEY\"\n",
    ")\n",
    "#-----------------------------------------------------#\n",
    "print(time.time() - t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
